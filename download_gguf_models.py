#!/usr/bin/env python3
"""
Script de t√©l√©chargement de mod√®les GGUF pour Wavestone Local AI Workbench.
Lit la configuration directement depuis models_config.py.
"""

import os
import argparse
import sys
from pathlib import Path
from huggingface_hub import hf_hub_download, HfApi
import logging

# ‚úÖ IMPORT DE LA CONFIGURATION PYTHON
try:
    from config.models_config import MODELS_DB, DOWNLOAD_SETTINGS
except ImportError:
    print("‚ùå Erreur : Impossible d'importer 'models_config.py'. V√©rifiez qu'il est dans le m√™me dossier.")
    sys.exit(1)

# Configuration du logging avec des couleurs si possible, sinon simple
logging.basicConfig(
    level=logging.INFO,
    format='%(message)s'
)
logger = logging.getLogger(__name__)

def check_model_availability(repo_id, filename):
    """V√©rifie si le mod√®le existe sur HF sans le t√©l√©charger (Dry Run)"""
    api = HfApi()
    try:
        # V√©rifie si le fichier existe dans le repo
        exists = api.file_exists(repo_id=repo_id, filename=filename)
        return exists
    except Exception as e:
        logger.error(f"    ‚îî‚îÄ‚îÄ ‚ö†Ô∏è Erreur d'acc√®s API: {e}")
        return False

def download_gguf_model(model_name, model_conf, local_dir, force=False, dry_run=False):
    """
    G√®re la logique de t√©l√©chargement ou de v√©rification d'un mod√®le.
    """
    repo_id = model_conf.get('repo_id')
    filename = model_conf.get('filename')
    
    if not repo_id or not filename:
        logger.warning(f"‚ö†Ô∏è Configuration incompl√®te pour {model_name} (repo_id ou filename manquant)")
        return None
    
    target_path = os.path.join(local_dir, filename)
    
    logger.info(f"ü§ñ {model_name}")
    logger.info(f"    ‚îú‚îÄ‚îÄ Repo: {repo_id}")
    logger.info(f"    ‚îî‚îÄ‚îÄ File: {filename}")

    # --- MODE DRY RUN (Test de connexion) ---
    if dry_run:
        logger.info("    ‚îú‚îÄ‚îÄ üß™ Mode Test (Dry Run)...")
        is_available = check_model_availability(repo_id, filename)
        if is_available:
            logger.info("    ‚îî‚îÄ‚îÄ ‚úÖ DISPONIBLE (Connexion OK)")
            return "dry_run_ok"
        else:
            logger.error("    ‚îî‚îÄ‚îÄ ‚ùå INACCESSIBLE (V√©rifier nom ou token)")
            return None

    # --- MODE T√âL√âCHARGEMENT ---
    
    # 1. V√©rification de l'existant
    if os.path.exists(target_path) and not force:
        file_size_mb = os.path.getsize(target_path) / (1024 * 1024)
        logger.info(f"    ‚îú‚îÄ‚îÄ ‚è≠Ô∏è  D√âJ√Ä PR√âSENT ({file_size_mb:.1f} MB)")
        logger.info(f"    ‚îî‚îÄ‚îÄ üìç {target_path}")
        return target_path

    # 2. T√©l√©chargement r√©el
    try:
        logger.info("    ‚îú‚îÄ‚îÄ üöÄ D√©marrage du t√©l√©chargement...")
        
        file_path = hf_hub_download(
            repo_id=repo_id,
            filename=filename,
            local_dir=local_dir,
            local_dir_use_symlinks=False,
            resume_download=True
        )
        
        logger.info("    ‚îî‚îÄ‚îÄ ‚úÖ T√âL√âCHARGEMENT TERMIN√â")
        return file_path
        
    except Exception as e:
        logger.error(f"    ‚îî‚îÄ‚îÄ ‚ùå ERREUR: {str(e)}")
        return None

def main():
    # Gestion des arguments en ligne de commande
    parser = argparse.ArgumentParser(description="T√©l√©chargeur de mod√®les GGUF Wavestone Workbench")
    parser.add_argument("--dry-run", action="store_true", help="V√©rifie uniquement l'acc√®s aux fichiers sans t√©l√©charger")
    parser.add_argument("--force", action="store_true", help="Force le re-t√©l√©chargement m√™me si le fichier existe")
    args = parser.parse_args()

    # 1. Charger les settings depuis la config Python
    local_dir = DOWNLOAD_SETTINGS.get('local_dir', './models_gguf')
    Path(local_dir).mkdir(parents=True, exist_ok=True)

    # 2. Convertir MODELS_DB (structure imbriqu√©e) en une liste plate pour le t√©l√©chargement
    models_to_download = []
    
    for family, variants in MODELS_DB.items():
        for model_variant, config in variants.items():
            # On ne traite que les mod√®les de type "local"
            if config.get("type") == "local":
                # On injecte le nom du variant pour l'affichage
                # On cr√©e une copie pour ne pas modifier le dictionnaire original en m√©moire
                download_item = config.copy()
                download_item['name'] = f"{family} - {model_variant}"
                models_to_download.append(download_item)

    # Header
    mode_str = "üß™ MODE TEST (DRY RUN)" if args.dry_run else "‚¨áÔ∏è  MODE T√âL√âCHARGEMENT"
    logger.info("=" * 60)
    logger.info(f"üì¶ WAVESTONE LOCAL AI WORKBENCH - MODEL DOWNLOADER")
    logger.info(f"{mode_str}")
    logger.info(f"üìÇ Destination: {local_dir}")
    logger.info(f"üî¢ Mod√®les locaux identifi√©s: {len(models_to_download)}")
    logger.info("=" * 60 + "\n")

    success_count = 0
    
    if not models_to_download:
        logger.warning("‚ö†Ô∏è Aucun mod√®le local trouv√© dans models_config.py.")
        return

    for i, model_conf in enumerate(models_to_download, 1):
        logger.info(f"[{i}/{len(models_to_download)}]")
        result = download_gguf_model(
            model_name=model_conf['name'], 
            model_conf=model_conf, 
            local_dir=local_dir, 
            force=args.force, 
            dry_run=args.dry_run
        )
        
        if result:
            success_count += 1
        logger.info("-" * 60)

    # R√©sum√©
    logger.info("\n" + "=" * 60)
    if args.dry_run:
        logger.info(f"üìã R√âSULTAT DU TEST: {success_count}/{len(models_to_download)} mod√®les accessibles")
    else:
        logger.info(f"üìã R√âSULTAT FINAL: {success_count}/{len(models_to_download)} mod√®les pr√™ts")
        if success_count == len(models_to_download):
            logger.info("\nüéâ Tout est pr√™t ! Vous pouvez lancer: streamlit run app.py")
    logger.info("=" * 60)

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        logger.info("\nüõë Interrompu par l'utilisateur")